{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.19008575 0.7848808  0.24119395 ... 0.9200101  0.37501767 0.        ]\n",
      " [0.18914689 0.78880644 0.23723298 ... 0.9255564  0.35775924 0.        ]\n",
      " [0.18889654 0.80558956 0.24458905 ... 0.9287978  0.33059838 0.        ]\n",
      " ...\n",
      " [0.21649872 0.77371603 0.11161409 ... 0.7025859  0.10991654 0.03018868]\n",
      " [0.19684547 0.82320106 0.11387749 ... 0.69178134 0.13453105 0.03018868]\n",
      " [0.18626776 0.82543397 0.11741406 ... 0.69812    0.15730655 0.03018868]]\n",
      "Epoch [1/100], Train Loss: 0.0014, Val Loss: 0.0012, MAPE: 6.52%\n",
      "保存模型: 验证损失最小的模型 (Val Loss: 0.0012)\n",
      "保存模型: 验证MAPE最小的模型 (MAPE: 6.52%)\n",
      "Epoch [2/100], Train Loss: 0.0006, Val Loss: 0.0009, MAPE: 5.56%\n",
      "保存模型: 验证损失最小的模型 (Val Loss: 0.0009)\n",
      "保存模型: 验证MAPE最小的模型 (MAPE: 5.56%)\n",
      "Epoch [3/100], Train Loss: 0.0004, Val Loss: 0.0008, MAPE: 5.39%\n",
      "保存模型: 验证损失最小的模型 (Val Loss: 0.0008)\n",
      "保存模型: 验证MAPE最小的模型 (MAPE: 5.39%)\n",
      "Epoch [4/100], Train Loss: 0.0003, Val Loss: 0.0009, MAPE: 5.77%\n",
      "Epoch [5/100], Train Loss: 0.0009, Val Loss: 0.0005, MAPE: 4.45%\n",
      "保存模型: 验证损失最小的模型 (Val Loss: 0.0005)\n",
      "保存模型: 验证MAPE最小的模型 (MAPE: 4.45%)\n",
      "Epoch [6/100], Train Loss: 0.0007, Val Loss: 0.0009, MAPE: 5.80%\n",
      "Epoch [7/100], Train Loss: 0.0002, Val Loss: 0.0005, MAPE: 4.30%\n",
      "保存模型: 验证损失最小的模型 (Val Loss: 0.0005)\n",
      "保存模型: 验证MAPE最小的模型 (MAPE: 4.30%)\n",
      "Epoch [8/100], Train Loss: 0.0002, Val Loss: 0.0005, MAPE: 4.15%\n",
      "保存模型: 验证损失最小的模型 (Val Loss: 0.0005)\n",
      "保存模型: 验证MAPE最小的模型 (MAPE: 4.15%)\n",
      "Epoch [9/100], Train Loss: 0.0002, Val Loss: 0.0006, MAPE: 4.81%\n",
      "Epoch [10/100], Train Loss: 0.0001, Val Loss: 0.0005, MAPE: 4.33%\n",
      "Epoch [11/100], Train Loss: 0.0004, Val Loss: 0.0004, MAPE: 3.83%\n",
      "保存模型: 验证损失最小的模型 (Val Loss: 0.0004)\n",
      "保存模型: 验证MAPE最小的模型 (MAPE: 3.83%)\n",
      "Epoch [12/100], Train Loss: 0.0008, Val Loss: 0.0004, MAPE: 3.77%\n",
      "保存模型: 验证损失最小的模型 (Val Loss: 0.0004)\n",
      "保存模型: 验证MAPE最小的模型 (MAPE: 3.77%)\n",
      "Epoch [13/100], Train Loss: 0.0003, Val Loss: 0.0004, MAPE: 3.90%\n",
      "Epoch [14/100], Train Loss: 0.0003, Val Loss: 0.0006, MAPE: 5.05%\n",
      "Epoch [15/100], Train Loss: 0.0002, Val Loss: 0.0004, MAPE: 3.76%\n",
      "保存模型: 验证损失最小的模型 (Val Loss: 0.0004)\n",
      "保存模型: 验证MAPE最小的模型 (MAPE: 3.76%)\n",
      "Epoch [16/100], Train Loss: 0.0001, Val Loss: 0.0004, MAPE: 3.73%\n",
      "保存模型: 验证损失最小的模型 (Val Loss: 0.0004)\n",
      "保存模型: 验证MAPE最小的模型 (MAPE: 3.73%)\n",
      "Epoch [17/100], Train Loss: 0.0001, Val Loss: 0.0003, MAPE: 3.65%\n",
      "保存模型: 验证损失最小的模型 (Val Loss: 0.0003)\n",
      "保存模型: 验证MAPE最小的模型 (MAPE: 3.65%)\n",
      "Epoch [18/100], Train Loss: 0.0001, Val Loss: 0.0004, MAPE: 3.79%\n",
      "Epoch [19/100], Train Loss: 0.0001, Val Loss: 0.0003, MAPE: 3.56%\n",
      "保存模型: 验证损失最小的模型 (Val Loss: 0.0003)\n",
      "保存模型: 验证MAPE最小的模型 (MAPE: 3.56%)\n",
      "Epoch [20/100], Train Loss: 0.0001, Val Loss: 0.0005, MAPE: 4.43%\n",
      "Epoch [21/100], Train Loss: 0.0003, Val Loss: 0.0004, MAPE: 3.94%\n",
      "Epoch [22/100], Train Loss: 0.0003, Val Loss: 0.0003, MAPE: 3.71%\n",
      "Epoch [23/100], Train Loss: 0.0002, Val Loss: 0.0004, MAPE: 3.82%\n",
      "Epoch [24/100], Train Loss: 0.0001, Val Loss: 0.0003, MAPE: 3.50%\n",
      "保存模型: 验证损失最小的模型 (Val Loss: 0.0003)\n",
      "保存模型: 验证MAPE最小的模型 (MAPE: 3.50%)\n",
      "Epoch [25/100], Train Loss: 0.0001, Val Loss: 0.0003, MAPE: 3.65%\n",
      "Epoch [26/100], Train Loss: 0.0002, Val Loss: 0.0004, MAPE: 3.75%\n",
      "Epoch [27/100], Train Loss: 0.0001, Val Loss: 0.0003, MAPE: 3.65%\n",
      "Epoch [28/100], Train Loss: 0.0001, Val Loss: 0.0003, MAPE: 3.60%\n",
      "Epoch [29/100], Train Loss: 0.0002, Val Loss: 0.0003, MAPE: 3.68%\n",
      "Epoch [30/100], Train Loss: 0.0001, Val Loss: 0.0004, MAPE: 3.78%\n",
      "Epoch [31/100], Train Loss: 0.0002, Val Loss: 0.0003, MAPE: 3.57%\n",
      "Epoch [32/100], Train Loss: 0.0001, Val Loss: 0.0003, MAPE: 3.53%\n",
      "保存模型: 验证损失最小的模型 (Val Loss: 0.0003)\n",
      "Epoch [33/100], Train Loss: 0.0002, Val Loss: 0.0003, MAPE: 3.54%\n",
      "Epoch [34/100], Train Loss: 0.0001, Val Loss: 0.0003, MAPE: 3.60%\n",
      "Epoch [35/100], Train Loss: 0.0001, Val Loss: 0.0003, MAPE: 3.51%\n",
      "Epoch [36/100], Train Loss: 0.0002, Val Loss: 0.0004, MAPE: 3.76%\n",
      "Epoch [37/100], Train Loss: 0.0003, Val Loss: 0.0003, MAPE: 3.44%\n",
      "保存模型: 验证损失最小的模型 (Val Loss: 0.0003)\n",
      "保存模型: 验证MAPE最小的模型 (MAPE: 3.44%)\n",
      "Epoch [38/100], Train Loss: 0.0002, Val Loss: 0.0004, MAPE: 3.82%\n",
      "Epoch [39/100], Train Loss: 0.0003, Val Loss: 0.0003, MAPE: 3.45%\n",
      "Epoch [40/100], Train Loss: 0.0001, Val Loss: 0.0003, MAPE: 3.37%\n",
      "保存模型: 验证损失最小的模型 (Val Loss: 0.0003)\n",
      "保存模型: 验证MAPE最小的模型 (MAPE: 3.37%)\n",
      "Epoch [41/100], Train Loss: 0.0001, Val Loss: 0.0003, MAPE: 3.43%\n",
      "Epoch [42/100], Train Loss: 0.0001, Val Loss: 0.0003, MAPE: 3.48%\n",
      "Epoch [43/100], Train Loss: 0.0002, Val Loss: 0.0005, MAPE: 4.74%\n",
      "Epoch [44/100], Train Loss: 0.0001, Val Loss: 0.0003, MAPE: 3.32%\n",
      "保存模型: 验证损失最小的模型 (Val Loss: 0.0003)\n",
      "保存模型: 验证MAPE最小的模型 (MAPE: 3.32%)\n",
      "Epoch [45/100], Train Loss: 0.0001, Val Loss: 0.0004, MAPE: 3.87%\n",
      "Epoch [46/100], Train Loss: 0.0003, Val Loss: 0.0003, MAPE: 3.66%\n",
      "Epoch [47/100], Train Loss: 0.0002, Val Loss: 0.0003, MAPE: 3.54%\n",
      "Epoch [48/100], Train Loss: 0.0001, Val Loss: 0.0003, MAPE: 3.48%\n",
      "Epoch [49/100], Train Loss: 0.0001, Val Loss: 0.0003, MAPE: 3.75%\n",
      "Epoch [50/100], Train Loss: 0.0002, Val Loss: 0.0003, MAPE: 3.62%\n",
      "Epoch [51/100], Train Loss: 0.0002, Val Loss: 0.0003, MAPE: 3.55%\n",
      "Epoch [52/100], Train Loss: 0.0001, Val Loss: 0.0003, MAPE: 3.37%\n",
      "Epoch [53/100], Train Loss: 0.0001, Val Loss: 0.0003, MAPE: 3.46%\n",
      "Epoch [54/100], Train Loss: 0.0002, Val Loss: 0.0003, MAPE: 3.30%\n",
      "保存模型: 验证损失最小的模型 (Val Loss: 0.0003)\n",
      "保存模型: 验证MAPE最小的模型 (MAPE: 3.30%)\n",
      "Epoch [55/100], Train Loss: 0.0002, Val Loss: 0.0003, MAPE: 3.58%\n",
      "Epoch [56/100], Train Loss: 0.0001, Val Loss: 0.0003, MAPE: 3.48%\n",
      "Epoch [57/100], Train Loss: 0.0001, Val Loss: 0.0003, MAPE: 3.63%\n",
      "Epoch [58/100], Train Loss: 0.0001, Val Loss: 0.0003, MAPE: 3.30%\n",
      "保存模型: 验证损失最小的模型 (Val Loss: 0.0003)\n",
      "Epoch [59/100], Train Loss: 0.0003, Val Loss: 0.0003, MAPE: 3.56%\n",
      "Epoch [60/100], Train Loss: 0.0002, Val Loss: 0.0003, MAPE: 3.36%\n",
      "Epoch [61/100], Train Loss: 0.0001, Val Loss: 0.0003, MAPE: 3.40%\n",
      "Epoch [62/100], Train Loss: 0.0002, Val Loss: 0.0003, MAPE: 3.43%\n",
      "Epoch [63/100], Train Loss: 0.0001, Val Loss: 0.0003, MAPE: 3.68%\n",
      "Epoch [64/100], Train Loss: 0.0002, Val Loss: 0.0003, MAPE: 3.46%\n",
      "Epoch [65/100], Train Loss: 0.0002, Val Loss: 0.0003, MAPE: 3.65%\n",
      "Epoch [66/100], Train Loss: 0.0002, Val Loss: 0.0003, MAPE: 3.30%\n",
      "保存模型: 验证MAPE最小的模型 (MAPE: 3.30%)\n",
      "Epoch [67/100], Train Loss: 0.0001, Val Loss: 0.0006, MAPE: 5.28%\n",
      "Epoch [68/100], Train Loss: 0.0001, Val Loss: 0.0003, MAPE: 3.33%\n",
      "Epoch [69/100], Train Loss: 0.0001, Val Loss: 0.0003, MAPE: 3.32%\n",
      "Epoch [70/100], Train Loss: 0.0002, Val Loss: 0.0007, MAPE: 5.46%\n",
      "Epoch [71/100], Train Loss: 0.0001, Val Loss: 0.0003, MAPE: 3.27%\n",
      "保存模型: 验证损失最小的模型 (Val Loss: 0.0003)\n",
      "保存模型: 验证MAPE最小的模型 (MAPE: 3.27%)\n",
      "Epoch [72/100], Train Loss: 0.0001, Val Loss: 0.0003, MAPE: 3.71%\n",
      "Epoch [73/100], Train Loss: 0.0001, Val Loss: 0.0003, MAPE: 3.27%\n",
      "保存模型: 验证MAPE最小的模型 (MAPE: 3.27%)\n",
      "Epoch [74/100], Train Loss: 0.0001, Val Loss: 0.0003, MAPE: 3.31%\n",
      "Epoch [75/100], Train Loss: 0.0002, Val Loss: 0.0003, MAPE: 3.42%\n",
      "Epoch [76/100], Train Loss: 0.0005, Val Loss: 0.0003, MAPE: 3.75%\n",
      "Epoch [77/100], Train Loss: 0.0002, Val Loss: 0.0003, MAPE: 3.32%\n",
      "Epoch [78/100], Train Loss: 0.0002, Val Loss: 0.0003, MAPE: 3.30%\n",
      "Epoch [79/100], Train Loss: 0.0001, Val Loss: 0.0003, MAPE: 3.71%\n",
      "Epoch [80/100], Train Loss: 0.0002, Val Loss: 0.0003, MAPE: 3.28%\n",
      "Epoch [81/100], Train Loss: 0.0001, Val Loss: 0.0003, MAPE: 3.32%\n",
      "Epoch [82/100], Train Loss: 0.0001, Val Loss: 0.0003, MAPE: 3.70%\n",
      "Epoch [83/100], Train Loss: 0.0001, Val Loss: 0.0003, MAPE: 3.55%\n",
      "Epoch [84/100], Train Loss: 0.0001, Val Loss: 0.0003, MAPE: 3.35%\n",
      "Epoch [85/100], Train Loss: 0.0001, Val Loss: 0.0003, MAPE: 3.61%\n",
      "Epoch [86/100], Train Loss: 0.0003, Val Loss: 0.0003, MAPE: 3.64%\n",
      "Epoch [87/100], Train Loss: 0.0003, Val Loss: 0.0003, MAPE: 3.39%\n",
      "Epoch [88/100], Train Loss: 0.0001, Val Loss: 0.0003, MAPE: 3.27%\n",
      "Epoch [89/100], Train Loss: 0.0001, Val Loss: 0.0003, MAPE: 3.37%\n",
      "Epoch [90/100], Train Loss: 0.0001, Val Loss: 0.0003, MAPE: 3.69%\n",
      "Epoch [91/100], Train Loss: 0.0002, Val Loss: 0.0003, MAPE: 3.34%\n",
      "Epoch [92/100], Train Loss: 0.0001, Val Loss: 0.0004, MAPE: 4.11%\n",
      "Epoch [93/100], Train Loss: 0.0002, Val Loss: 0.0003, MAPE: 3.39%\n",
      "Epoch [94/100], Train Loss: 0.0001, Val Loss: 0.0003, MAPE: 3.44%\n",
      "Epoch [95/100], Train Loss: 0.0004, Val Loss: 0.0004, MAPE: 3.87%\n",
      "Epoch [96/100], Train Loss: 0.0003, Val Loss: 0.0006, MAPE: 5.06%\n",
      "Epoch [97/100], Train Loss: 0.0001, Val Loss: 0.0003, MAPE: 3.36%\n",
      "Epoch [98/100], Train Loss: 0.0001, Val Loss: 0.0006, MAPE: 4.91%\n",
      "Epoch [99/100], Train Loss: 0.0001, Val Loss: 0.0003, MAPE: 3.36%\n",
      "Epoch [100/100], Train Loss: 0.0001, Val Loss: 0.0003, MAPE: 3.36%\n",
      "已加载验证集上 MSE 表现最好的模型。\n",
      "修复后的数据已保存为 'Repaired_Train_Data.csv' 文件。\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "\n",
    "# 加载数据\n",
    "file_path = 'Train data.csv'\n",
    "train_data = pd.read_csv(file_path, parse_dates=['DateTime']).sort_values(by='DateTime')\n",
    "\n",
    "# 设置异常检测的阈值\n",
    "threshold = 100\n",
    "train_data['is_anomaly'] = train_data['Load'] < threshold\n",
    "\n",
    "# 定义季节划分函数\n",
    "def assign_season(month):\n",
    "    if month in [3, 4, 5]:\n",
    "        return 0  # 春季\n",
    "    elif month in [6, 7, 8]:\n",
    "        return 1  # 夏季\n",
    "    elif month in [9, 10, 11]:\n",
    "        return 2  # 秋季\n",
    "    else:\n",
    "        return 3  # 冬季\n",
    "\n",
    "# 提取时间标签特征\n",
    "train_data['day_of_week'] = train_data['DateTime'].dt.dayofweek  # 0-6 表示周一到周日\n",
    "train_data['hour_of_day'] = train_data['DateTime'].dt.hour       # 0-23 表示一天的小时\n",
    "train_data['season'] = train_data['DateTime'].dt.month.apply(assign_season)  # 按中国大陆季节划分\n",
    "\n",
    "\n",
    "# 选择特征并标准化\n",
    "features = ['Temperature', 'Humidity', 'Wind_speed', 'Precipitation']\n",
    "scaler = MinMaxScaler()\n",
    "train_data[features + ['Load']] = scaler.fit_transform(train_data[features + ['Load']])\n",
    "\n",
    "# 从 MinMaxScaler 中提取参数\n",
    "data_min = scaler.data_min_\n",
    "data_max = scaler.data_max_\n",
    "scale = scaler.scale_\n",
    "\n",
    "\n",
    "# 构建时间序列数据，并跳过包含异常数据的窗口\n",
    "sequence_length = 24\n",
    "\n",
    "def create_sequences_with_time_labels(data, seq_length, target_col):\n",
    "    sequences = []\n",
    "    targets = []\n",
    "    time_labels = []\n",
    "    for i in range(len(data) - seq_length):\n",
    "        window = data.iloc[i:i+seq_length]\n",
    "        # 检查窗口中是否有异常数据\n",
    "        if window['is_anomaly'].sum() == 0:  # 如果窗口中没有异常数据\n",
    "            # 获取前6个时间步的负荷和辅助特征\n",
    "            sequence = window[features + [target_col]].values.flatten()\n",
    "            # 添加当前时刻的辅助特征到序列末尾\n",
    "            current_features = data.iloc[i + seq_length][features].values\n",
    "            full_sequence = np.concatenate((sequence, current_features))\n",
    "            sequences.append(full_sequence)\n",
    "            targets.append(data.iloc[i + seq_length][target_col])\n",
    "            # 提取时间标签\n",
    "            time_labels.append(data.iloc[i + seq_length][['day_of_week', 'hour_of_day', 'season']].values)\n",
    "    return np.array(sequences,dtype=np.float32), np.array(targets,dtype=np.float32), np.array(time_labels,dtype=np.int64)\n",
    "\n",
    "# 构建数据集，包含时间标签\n",
    "X, y, time_labels = create_sequences_with_time_labels(train_data, sequence_length, 'Load')\n",
    "print(X)\n",
    "\n",
    "X = torch.tensor(X, dtype=torch.float32)\n",
    "y = torch.tensor(y, dtype=torch.float32)\n",
    "time_labels = np.array(time_labels, dtype=np.int64)  # 转换为整数类型\n",
    "time_labels = torch.tensor(time_labels, dtype=torch.long)\n",
    "\n",
    "# 划分训练集和验证集（80%训练集，20%验证集）\n",
    "dataset = TensorDataset(X, time_labels, y)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32)\n",
    "\n",
    "\n",
    "# 定义MLP模型，包含时间Embedding\n",
    "class MLPModelWithEmbedding(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, day_emb_dim=4, hour_emb_dim=4, season_emb_dim=4):\n",
    "        super(MLPModelWithEmbedding, self).__init__()\n",
    "        \n",
    "        # 时间标签的Embedding层\n",
    "        self.day_embedding = nn.Embedding(7, day_emb_dim)\n",
    "        self.hour_embedding = nn.Embedding(24, hour_emb_dim)\n",
    "        self.season_embedding = nn.Embedding(4, season_emb_dim)\n",
    "        \n",
    "        # 计算总输入维度\n",
    "        time_embedding_dim = day_emb_dim + hour_emb_dim + season_emb_dim\n",
    "        total_input_size = input_size + time_embedding_dim\n",
    "\n",
    "        # MLP层\n",
    "        self.fc1 = nn.Linear(total_input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size // 2)\n",
    "        self.fc3 = nn.Linear(hidden_size // 2, output_size)\n",
    "    \n",
    "    def forward(self, x, time_labels):\n",
    "        # 时间标签embedding\n",
    "        day_emb = self.day_embedding(time_labels[:, 0])\n",
    "        hour_emb = self.hour_embedding(time_labels[:, 1])\n",
    "        season_emb = self.season_embedding(time_labels[:, 2])\n",
    "        \n",
    "        # 合并输入\n",
    "        time_emb = torch.cat((day_emb, hour_emb, season_emb), dim=1)\n",
    "        x = torch.cat((x, time_emb), dim=1)\n",
    "        \n",
    "        # MLP前向传播\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc3(out)\n",
    "        return out\n",
    "\n",
    "# 初始化MLP模型、损失函数和优化器\n",
    "input_size = X.shape[1]\n",
    "model = MLPModelWithEmbedding(input_size=input_size, hidden_size=128, output_size=1)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# 定义最小验证损失和最小MAPE的初始值\n",
    "best_val_loss = float('inf')\n",
    "best_mape = float('inf')\n",
    "\n",
    "# 训练模型并在每个epoch进行验证\n",
    "num_epochs = 100\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for X_batch, time_labels_batch, y_batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_batch, time_labels_batch)\n",
    "        loss = criterion(outputs, y_batch.view(-1, 1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    # 在验证集上评估模型\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    mape = 0\n",
    "    with torch.no_grad():\n",
    "        for X_val, time_labels_val, y_val in val_loader:\n",
    "            val_outputs = model(X_val, time_labels_val)\n",
    "            val_loss += criterion(val_outputs, y_val.view(-1, 1)).item()\n",
    "            \n",
    "            # 计算MAPE\n",
    "            y_true = y_val.view(-1, 1)\n",
    "            y_pred = val_outputs\n",
    "            mape += (torch.abs((y_true - y_pred) / y_true).mean().item()) * 100  # 转换为百分比\n",
    "\n",
    "    # 计算平均的验证损失和MAPE\n",
    "    val_loss /= len(val_loader)\n",
    "    mape /= len(val_loader)\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Train Loss: {loss.item():.4f}, Val Loss: {val_loss:.4f}, MAPE: {mape:.2f}%')\n",
    "    \n",
    "    # 保存验证损失最小的模型\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        torch.save(model.state_dict(), 'best_val_loss_model.pth')\n",
    "        print(f\"保存模型: 验证损失最小的模型 (Val Loss: {best_val_loss:.4f})\")\n",
    "        \n",
    "    # 保存MAPE最小的模型\n",
    "    if mape < best_mape:\n",
    "        best_mape = mape\n",
    "        torch.save(model.state_dict(), 'best_mape_model.pth')\n",
    "        print(f\"保存模型: 验证MAPE最小的模型 (MAPE: {best_mape:.2f}%)\")\n",
    "\n",
    "# 最终保存的两个模型文件：\n",
    "# 'best_val_loss_model.pth' 保存验证集上损失最小的模型\n",
    "# 'best_mape_model.pth' 保存验证集上MAPE最小的模型\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# 定义 MinMaxScaler 的参数（在训练阶段确定的参数）\n",
    "data_min = scaler.data_min_\n",
    "data_max = scaler.data_max_\n",
    "scale = scaler.scale_\n",
    "\n",
    "# 反向标准化函数\n",
    "def inverse_min_max_scale(scaled_value, data_min, data_max):\n",
    "    return scaled_value * (data_max - data_min) + data_min\n",
    "\n",
    "# 手动标准化函数\n",
    "def manual_min_max_scale(data, data_min, scale):\n",
    "    return (data - data_min) * scale\n",
    "\n",
    "# 滚动修复异常值\n",
    "def rolling_repair_anomalies(original_data, model, sequence_length, data_min, data_max, scale):\n",
    "    repaired_data = original_data.copy()\n",
    "    model.eval()  # 设置模型为评估模式\n",
    "    with torch.no_grad():\n",
    "        # 找到所有异常时刻的索引\n",
    "        anomaly_indices = repaired_data[repaired_data['is_anomaly']].index\n",
    "        for i in anomaly_indices:\n",
    "            # 提取前24个时间步的特征和负荷数据（未标准化）\n",
    "            sequence = original_data.iloc[i-sequence_length:i][features + ['Load']].values\n",
    "\n",
    "            # 对前24个时间步的数据进行手动标准化\n",
    "            sequence = manual_min_max_scale(sequence, data_min, scale).astype(np.float32)  # 确保类型为 np.float32\n",
    "            sequence = sequence.flatten()  # 平铺成一维数组\n",
    "            \n",
    "            # 获取当前异常时刻的辅助特征并手动标准化\n",
    "            current_features = original_data.iloc[i][features].values\n",
    "            current_features = manual_min_max_scale(current_features, data_min[:len(features)], scale[:len(features)]).astype(np.float32)\n",
    "            \n",
    "            # 合并前24个时间步的标准化特征和当前时刻的标准化辅助特征\n",
    "            full_sequence = np.concatenate((sequence, current_features)).astype(np.float32)\n",
    "            \n",
    "            # 转换为 Tensor\n",
    "            full_sequence = torch.tensor(full_sequence, dtype=torch.float32).unsqueeze(0)\n",
    "            \n",
    "            # 提取时间标签（确保整数类型 np.int32）\n",
    "            time_labels = original_data.iloc[i][['day_of_week', 'hour_of_day', 'season']].values.astype(np.int32)\n",
    "            time_labels = torch.tensor(time_labels, dtype=torch.long).unsqueeze(0)\n",
    "            \n",
    "            # 使用模型进行预测（得到的是标准化后的负荷值）\n",
    "            scaled_repaired_value = model(full_sequence, time_labels).item()\n",
    "            \n",
    "            # 对预测值进行反向标准化\n",
    "            original_repaired_value = inverse_min_max_scale(scaled_repaired_value, data_min[-1], data_max[-1])\n",
    "            \n",
    "            # 将反向标准化后的预测值替换到 `repaired_data` 和 `original_data` 中的异常负荷值\n",
    "            repaired_data.at[i, 'Load'] = original_repaired_value\n",
    "            original_data.at[i, 'Load'] = original_repaired_value  # 确保后续读取时得到已修复的值\n",
    "            \n",
    "    return repaired_data\n",
    "\n",
    "\n",
    "# 读取原始文件数据\n",
    "file_path = 'Train data.csv'\n",
    "original_data = pd.read_csv(file_path, parse_dates=['DateTime']).sort_values(by='DateTime')\n",
    "\n",
    "# 设置异常检测的阈值\n",
    "threshold = 100\n",
    "original_data['is_anomaly'] = original_data['Load'] < threshold\n",
    "\n",
    "# 定义季节划分函数\n",
    "def assign_season(month):\n",
    "    if month in [3, 4, 5]:\n",
    "        return 0  # 春季\n",
    "    elif month in [6, 7, 8]:\n",
    "        return 1  # 夏季\n",
    "    elif month in [9, 10, 11]:\n",
    "        return 2  # 秋季\n",
    "    else:\n",
    "        return 3  # 冬季\n",
    "\n",
    "# 提取时间标签特征\n",
    "original_data['day_of_week'] = original_data['DateTime'].dt.dayofweek  # 0-6 表示周一到周日\n",
    "original_data['hour_of_day'] = original_data['DateTime'].dt.hour       # 0-23 表示一天的小时\n",
    "original_data['season'] = original_data['DateTime'].dt.month.apply(assign_season)  # 按中国大陆季节划分\n",
    "\n",
    "\n",
    "# 定义特征列表\n",
    "features = ['Temperature', 'Humidity', 'Wind_speed', 'Precipitation']\n",
    "\n",
    "# 加载验证集上 MSE 最小的模型\n",
    "model = MLPModelWithEmbedding(input_size=input_size, hidden_size=128, output_size=1)\n",
    "model.load_state_dict(torch.load('best_val_loss_model.pth'))\n",
    "print(\"已加载验证集上 MSE 表现最好的模型。\")\n",
    "\n",
    "# 修复异常数据\n",
    "sequence_length = 24  # 使用前24个时间步\n",
    "repaired_data = rolling_repair_anomalies(original_data, model, sequence_length, data_min, data_max, scale)\n",
    "\n",
    "# 保存修复后的数据\n",
    "repaired_data.to_csv('Repaired_Train_Data.csv', index=False)\n",
    "print(\"修复后的数据已保存为 'Repaired_Train_Data.csv' 文件。\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "optim",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
