{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import random\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "\n",
    "# 设置随机种子\n",
    "# 刚过的23岁生日，所以seed=23\n",
    "seed = 23\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "# 文件列表\n",
    "file_list = [\"Labeled_\" + file for file in [\"February.csv\", \"April.csv\", \"June.csv\", \"August.csv\", \"October.csv\", \"December.csv\"]]\n",
    "\n",
    "# 参数设置\n",
    "Seq_len = 7*24  # 历史数据长度（7 天）\n",
    "Pre_len = 24      # 预测长度（24 小时）\n",
    "# 哈哈哈哈我用的特征被我删掉啦，请你自己摸索！！\n",
    "features = []\n",
    "\n",
    "data = pd.read_csv('Labeled_Train Data.csv')\n",
    "data = data.drop(columns=['DateTime'])\n",
    "data_np = data.to_numpy().astype(np.float32)\n",
    "\n",
    "features_indices = [data.columns.get_loc(f) for f in features]\n",
    "\n",
    "Power_Inputs_list = []\n",
    "# 处理主数据\n",
    "for i in range(Seq_len + Pre_len, len(data_np)):\n",
    "    Power_Input = data_np[i - (Seq_len + Pre_len):i, features_indices]\n",
    "    Power_Inputs_list.append(Power_Input)\n",
    "\n",
    "# 转换为 NumPy 数组\n",
    "# feature维度的最后一个特征是Load\n",
    "# (num_samples, Seq_len + Pre_len, len(features))\n",
    "Power_Inputs = np.array(Power_Inputs_list)\n",
    "print(Power_Inputs.shape)\n",
    "\n",
    "# 处理其他月份的数据\n",
    "for file_name in file_list:\n",
    "    data = pd.read_csv(file_name)\n",
    "    data = data.drop(columns=['DateTime'])\n",
    "    data_np = data.to_numpy().astype(np.float32)\n",
    "    \n",
    "    for i in range(Seq_len + Pre_len, len(data_np)-24):\n",
    "        Power_Input = data_np[i - (Seq_len + Pre_len):i, features_indices]\n",
    "        Power_Inputs_list.append(Power_Input)\n",
    "Power_Inputs = np.array(Power_Inputs_list)\n",
    "print(Power_Inputs.shape)\n",
    "\n",
    "# 初始化归一化器\n",
    "scaler_Load = StandardScaler()\n",
    "scaler_Feature = StandardScaler()\n",
    "\n",
    "# 提取负荷特征和其他数值特征的索引\n",
    "load_index = features.index('Load')\n",
    "# 是的这里也被我删去了！请你自己摸索！\n",
    "num_feature_indices = []\n",
    "\n",
    "# 归一化非负荷数值特征\n",
    "Power_Inputs[:, :, num_feature_indices] = scaler_Feature.fit_transform(\n",
    "    Power_Inputs[:, :, num_feature_indices].reshape(-1,len(num_feature_indices))\n",
    ").reshape(Power_Inputs[:, :, num_feature_indices].shape)\n",
    "\n",
    "# 单独归一化负荷特征\n",
    "Power_Inputs[:, :, load_index] = scaler_Load.fit_transform(\n",
    "    Power_Inputs[:, :, load_index].reshape(-1, 1)\n",
    ").reshape(Power_Inputs[:, :, load_index].shape)\n",
    "\n",
    "# 数据集划分\n",
    "Data_train, Data_Temp = train_test_split(Power_Inputs, test_size=0.4, shuffle=False)\n",
    "Data_val, Data_test = train_test_split(Data_Temp, test_size=0.5, shuffle=True, random_state=seed)\n",
    "\n",
    "# 自定义 TimePower Dataset\n",
    "class TimePowerDataset(Dataset):\n",
    "    def __init__(self, Data, Seq_len, Pre_len=None):\n",
    "        self.Data = torch.tensor(Data, dtype=torch.float32)\n",
    "        self.Seq_len = Seq_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.Data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        En_X = self.Data[idx, :self.Seq_len, -1].unsqueeze(1)\n",
    "        Ex_X = self.Data[idx, :, :-1]\n",
    "        En_y = self.Data[idx, self.Seq_len:, -1].unsqueeze(1)\n",
    "        return En_X, Ex_X, En_y\n",
    "\n",
    "# 数据加载\n",
    "batch_size = 10240\n",
    "train_dataset = TimePowerDataset(Data=Data_train, Seq_len=Seq_len)\n",
    "val_dataset = TimePowerDataset(Data=Data_val, Seq_len=Seq_len)\n",
    "test_dataset = TimePowerDataset(Data=Data_test, Seq_len=Seq_len)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "print(f\"训练集大小: {len(train_dataset)}, 验证集大小: {len(val_dataset)}, 测试集大小: {len(test_dataset)}\")\n",
    "# 打印数据shape\n",
    "# for i, (En_X, Ex_X, En_y) in enumerate(train_dataset):\n",
    "#     print('En_X:',En_X.shape, 'Ex_X:',Ex_X.shape, 'En_y:',En_y.shape)\n",
    "#     print(scaler_Load.inverse_transform(En_y).shape)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts\n",
    "from TimePower import TimePower\n",
    "\n",
    "# 设置设备\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "seq_len=24* 7        # Endogenous变量长度\n",
    "pre_len=24          # 待预测时段长度\n",
    "d_model=512         # Patch of Endogenous Variables和 Exogenous Variables嵌入长度\n",
    "patch_len=24        # 单个Patch长度\n",
    "n_heads=8           # Num of Multihead\n",
    "d_ff=2048           # FFN中间层维度，一般是4*d_model\n",
    "e_layers=10          # 编码器层数\n",
    "\n",
    "# TimePower模型的初始化\n",
    "model = TimePower(seq_len=seq_len,pre_len=pre_len,d_model=d_model,patch_len=patch_len,n_heads=n_heads,d_ff=d_ff,e_layers=e_layers,use_norm=True,time_embed=5)\n",
    "\n",
    "\n",
    "# 定义损失函数和优化器\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=2e-4)\n",
    "# scheduler = CosineAnnealingWarmRestarts(optimizer, T_0=10, T_mult=2, eta_min=1e-6)\n",
    "\n",
    "# 初始化用于可视化损失的列表\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "best_mape = float(\"inf\")\n",
    "best_mse = float(\"inf\")\n",
    "num_epochs = 30        # 总训练轮数\n",
    "\n",
    "# 模型加载到设备\n",
    "model.to(device)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    start_time = time.time()\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    # 训练阶段\n",
    "    for i, (En_X, Ex_X, En_y) in enumerate(train_loader):\n",
    "        \n",
    "        En_X = En_X.to(device)\n",
    "        Ex_X = Ex_X.to(device)\n",
    "        En_y = En_y.to(device)\n",
    "        \n",
    "        # 前向传播\n",
    "        outputs = model(En_X, Ex_X)\n",
    "        \n",
    "        # 计算损失\n",
    "        loss = criterion(outputs, En_y)\n",
    "\n",
    "        # 反向传播和优化\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    # 打印训练损失\n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    train_losses.append(epoch_loss)\n",
    "    print(\n",
    "        f\"Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}, Train_time Cost: {(time.time() - start_time):.4f}\"\n",
    "    )\n",
    "\n",
    "    # 验证阶段\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_mape = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for En_X, Ex_X, En_y in val_loader:\n",
    "            En_X = En_X.to(device)\n",
    "            Ex_X = Ex_X.to(device)\n",
    "            En_y = En_y.to(device)\n",
    "        \n",
    "            # 前向传播\n",
    "            outputs = model(En_X, Ex_X)\n",
    "            \n",
    "            # 反归一化\n",
    "            outputs = scaler_Load.inverse_transform(outputs.cpu().numpy().reshape(-1,1))\n",
    "            targets = scaler_Load.inverse_transform(En_y.cpu().numpy().reshape(-1,1))\n",
    "            outputs = torch.from_numpy(outputs).to(device)\n",
    "            targets = torch.from_numpy(targets).to(device)\n",
    "\n",
    "            # 计算损失和 MAPE\n",
    "            loss = criterion(outputs, targets)\n",
    "            val_loss += loss.item()\n",
    "            mape = (torch.mean(torch.abs((targets - outputs) / (targets + 1e-8)).clamp(min=1e-8))* 100)\n",
    "            val_mape += mape.item()\n",
    "\n",
    "    val_loss /= len(val_loader)\n",
    "    val_mape /= len(val_loader)\n",
    "    val_losses.append(val_loss)\n",
    "    print(f\"Validation Loss: {val_loss:.4f}, Validation MAPE: {val_mape:.4f}%\")\n",
    "\n",
    "    # 保存最优模型\n",
    "    if val_mape < best_mape:\n",
    "        best_mape = val_mape\n",
    "        torch.save(model.state_dict(), \"best_mape_model.pth\")\n",
    "        print(f\"Model saved at epoch {epoch+1} with MAPE: {val_mape:.4f}%\")\n",
    "\n",
    "    if val_loss < best_mse:\n",
    "        best_mse = val_loss\n",
    "        torch.save(model.state_dict(), \"best_mse_model.pth\")\n",
    "        print(f\"Model saved at epoch {epoch+1} with MSE: {val_loss:.4f}\")\n",
    "\n",
    "    # 每 50 个 epoch 绘制一次训练和验证损失\n",
    "    if (epoch + 1) % 30 == 0:\n",
    "        fig, ax1 = plt.subplots(figsize=(10, 5), facecolor=\"white\")\n",
    "        ax1.plot(range(1, epoch + 2), train_losses, \"b-\", label=\"Training Loss\")\n",
    "        ax1.set_xlabel(\"Epoch\")\n",
    "        ax1.set_ylabel(\"Training Loss\", color=\"b\")\n",
    "        ax1.tick_params(axis=\"y\", labelcolor=\"b\")\n",
    "\n",
    "        ax1_twin = ax1.twinx()\n",
    "        ax1_twin.plot(range(1, epoch + 2), val_losses, \"r-\", label=\"Validation Loss\")\n",
    "        ax1_twin.set_ylabel(\"Validation Loss\", color=\"r\")\n",
    "        ax1_twin.tick_params(axis=\"y\", labelcolor=\"r\")\n",
    "        ax1.set_title(\"Training and Validation Loss Over Epochs\")\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "# 保存最终模型\n",
    "torch.save(model.state_dict(), \"final_model.pth\")\n",
    "print(\"Final model saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts\n",
    "from TimePower import TimePower\n",
    "\n",
    "\n",
    "\n",
    "# 设置设备\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "criterion = nn.MSELoss()\n",
    "val_losses = []\n",
    "\n",
    "seq_len=24* 7        # Endogenous变量长度\n",
    "pre_len=24          # 待预测时段长度\n",
    "d_model=512         # Patch of Endogenous Variables和 Exogenous Variables嵌入长度\n",
    "patch_len=24        # 单个Patch长度\n",
    "n_heads=8           # Num of Multihead\n",
    "d_ff=2048           # FFN中间层维度，一般是4*d_model\n",
    "e_layers=10          # 编码器层数\n",
    "time_embed = 5      # 时间特征嵌入维度\n",
    "\n",
    "# TimePower模型的初始化\n",
    "model = TimePower(seq_len=seq_len,pre_len=pre_len,d_model=d_model,patch_len=patch_len,n_heads=n_heads,d_ff=d_ff,e_layers=e_layers,use_norm=True,time_embed=time_embed)\n",
    "# 加载最优模型的参数（例如保存为 'best_mse_model.pth'）\n",
    "model.load_state_dict(torch.load('best_mse_model.pth', map_location=torch.device('cpu')))\n",
    "model.to(torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"))\n",
    "\n",
    "model.eval()\n",
    "val_loss = 0.0\n",
    "val_mape = 0.0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for En_X, Ex_X, En_y in test_loader:\n",
    "        En_X = En_X.to(device)\n",
    "        Ex_X = Ex_X.to(device)\n",
    "        En_y = En_y.to(device)\n",
    "    \n",
    "        # 前向传播\n",
    "        outputs = model(En_X, Ex_X)\n",
    "        \n",
    "        # 反归一化\n",
    "        outputs = scaler_Load.inverse_transform(outputs.cpu().numpy().reshape(-1,1))\n",
    "        targets = scaler_Load.inverse_transform(En_y.cpu().numpy().reshape(-1,1))\n",
    "        outputs = torch.from_numpy(outputs).to(device)\n",
    "        targets = torch.from_numpy(targets).to(device)\n",
    "\n",
    "        # 计算损失和 MAPE\n",
    "        loss = criterion(outputs, targets)\n",
    "        val_loss += loss.item()\n",
    "        mape = (\n",
    "            torch.mean(torch.abs((targets - outputs) / (targets + 1e-8)).clamp(min=1e-8))\n",
    "            * 100\n",
    "        )\n",
    "        val_mape += mape.item()\n",
    "\n",
    "val_loss /= len(val_loader)\n",
    "val_mape /= len(val_loader)\n",
    "val_losses.append(val_loss)\n",
    "print(f\"Validation Loss: {val_loss:.4f}, Validation MAPE: {val_mape:.4f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "optim",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
